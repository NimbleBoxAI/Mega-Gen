{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ea9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pylcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9270f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(s1:str, s2:str, model_name='paraphrase-mpnet-base-v2'):\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # encode sentences to get their embeddings\n",
    "    embedding1 = model.encode(s1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(s2, convert_to_tensor=True)\n",
    "    \n",
    "    # compute similarity scores of two embeddings\n",
    "    cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    \n",
    "    return cosine_scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b30f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic(s1:str):\n",
    "    # Returns the topic extracted from the entire output.\n",
    "    \n",
    "    return s1[:s1.find('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4aedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similarity(s1:str, s2:str):\n",
    "    \n",
    "    print(f'String 1 : {s1}')\n",
    "    print(f'String 2 : {s2}\\n')\n",
    "    \n",
    "    print('Similarity :',similarity(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ce5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfile = open('../data/I2_1_1000.txt','r')\n",
    "biz_ideas = [line.rstrip('\\n') for line in txtfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be0da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,1):\n",
    "    print(i,topic(biz_ideas[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23cc3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 1 : Concrete Cutting and Grinding business\n",
      "String 2 : Con-crete Company\n",
      "\n",
      "Similarity : 0.2693554759025574\n"
     ]
    }
   ],
   "source": [
    "compare_similarity(topic(biz_ideas[13]), topic(biz_ideas[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29176a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data:list):\n",
    "    \n",
    "    data = [datum.lower() for datum in data]\n",
    "    data = [datum for datum in set(data)]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11a7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(s1:str, s2:str):\n",
    "    \n",
    "    if len(s1) > len(s2):\n",
    "        return pylcs.lcs(s1,s2)/float(len(s1))\n",
    "    else:\n",
    "        return pylcs.lcs(s1,s2)/float(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1755c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap('beauty salon','a beauty salon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b686641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small business\n",
      "internet internet service\n",
      "diving and snorkeling business\n",
      "grocery and home shopping\n",
      "web designing service\n"
     ]
    }
   ],
   "source": [
    "# Create a list of topics from the corpus\n",
    "\n",
    "topics_unprocessed = []\n",
    "\n",
    "for idea in biz_ideas:\n",
    "\n",
    "    topics_unprocessed.append(topic(idea))\n",
    "\n",
    "topics = preprocess(topics_unprocessed)\n",
    "\n",
    "for topic_ in topics[:5]:\n",
    "    print(topic_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dba5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "topics_embeddings_unprocessed = model.encode(topics_unprocessed)\n",
    "topics_embeddings = model.encode(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef69da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 768)\n",
      "(628, 768)\n"
     ]
    }
   ],
   "source": [
    "print(topics_embeddings_unprocessed.shape)\n",
    "print(topics_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "311c39a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Beauty Parlor \n",
      "\n",
      "Top 10 most similar sentences in corpus:\n",
      "beauty salon (Score: 0.9091)\n",
      "a beauty salon (Score: 0.9033)\n",
      "beauty shop (Score: 0.8997)\n",
      "beauty salons (Score: 0.8859)\n",
      "hair care salon (Score: 0.7918)\n",
      "a hair salon (Score: 0.7792)\n",
      "hair and beauty salons (Score: 0.7688)\n",
      "hairdressing salon (Score: 0.7607)\n",
      "hair and grooming salon (Score: 0.7514)\n",
      "hair and nail salon (Score: 0.7510)\n"
     ]
    }
   ],
   "source": [
    "# Top K similar ideas\n",
    "\n",
    "topic_query = 'Beauty Parlor'\n",
    "query_embedding = model.encode(topic_query)\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, topics_embeddings)[0]\n",
    "top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "\"\"\"\n",
    "filtered_results = []\n",
    "\n",
    "for i in range(len(top_results)-1):\n",
    "    filtered = pylcs.lcs2_of_list(top_results[i], top_results[i:]) / float(len(top_results[i])) < 0.7\n",
    "    filtered_results.append(top_results[filtered])\n",
    "\"\"\"   \n",
    "\n",
    "print(\"Sentence:\", topic_query, \"\\n\")\n",
    "print(f'Top {top_k} most similar sentences in corpus:')\n",
    "\n",
    "for idx in top_results[0:top_k]:\n",
    "    print(topics[idx], \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7b4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering : KMeans\n",
    "\n",
    "def kmeans(num_clusters, data:list):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "        \n",
    "    clustering_model = KMeans(n_clusters = num_clusters)\n",
    "    clustering_model.fit(data)\n",
    "    cluster_assignment = clustering_model.labels_\n",
    "\n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f498ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_k(data:list):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    import math\n",
    "    \n",
    "    dists = []\n",
    "    K = range(1,70)\n",
    "        \n",
    "    for n in K:\n",
    "        k_model = KMeans(n_clusters = n)\n",
    "        k_model.fit(data)\n",
    "        dists.append(k_model.inertia_)\n",
    "        \n",
    "    def calc_dist(x1,y1,a,b,c):\n",
    "        return abs((a*x1 + b*y1 + c))/(math.sqrt(a**2 + b**2))\n",
    "        \n",
    "    a = dists[0] - dists[-1]\n",
    "    b = K[-1] - K[0]\n",
    "    c1 = K[0] * dists[-1]\n",
    "    c2 = K[-1] * dists[0]\n",
    "    c = c1 - c2\n",
    "        \n",
    "    dists_line = []\n",
    "\n",
    "    for k in range(K[-1]):\n",
    "        dists_line.append(calc_dist(K[k], dists[k], a, b, c))\n",
    "            \n",
    "    num_clusters = dists_line.index(max(dists_line))+1\n",
    "        \n",
    "    return num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23772caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Approach: DBSCAN (Does not seem to work well with semantics)\n",
    "\n",
    "def dbscan(data:list):\n",
    "    \n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    db_default = DBSCAN(eps = 0.0375, min_samples = 3).fit(data)\n",
    "    cluster_assignment = db_default.labels_\n",
    "\n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac13288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dims(data, alg='tsne', num_components=2):\n",
    "    \n",
    "    topics_red = None\n",
    "    \n",
    "    if alg == 'tsne':\n",
    "        \n",
    "        from sklearn.manifold import TSNE\n",
    "\n",
    "        topics_red = TSNE(n_components=num_components).fit_transform(data)\n",
    "        \n",
    "    elif alg == 'pca':\n",
    "        \n",
    "        from sklearn.decomposition import PCA\n",
    "        topics_red = PCA(n_components=num_components,svd_solver='full').fit_transform(data)\n",
    "            \n",
    "    return topics_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d82883bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clusters(num_clusters, cluster_assignment, topics):\n",
    "    \n",
    "    for i in range(num_clusters):\n",
    "        print()\n",
    "        print(f'Cluster {i + 1} contains:')\n",
    "        clust_sent = np.where(cluster_assignment == i)\n",
    "        for k in clust_sent[0]:\n",
    "            print(f'- {topics[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c807b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means\n",
    "\n",
    "# Define number of clusters or auto estimate optimum using intertia\n",
    "num_clusters = optimize_k(topics_embeddings)\n",
    "\n",
    "# Reduce Dimentions using TSNE or PCA\n",
    "topics_red = reduce_dims(topics_embeddings,alg='tsne',num_components=2)\n",
    "\n",
    "# Apply K-Means Clustering\n",
    "cluster_assignment = kmeans(num_clusters=num_clusters, data=topics_red) # data=topics_embeddings, topics_red\n",
    "\n",
    "# Print clusters cohesively\n",
    "print_clusters(num_clusters, cluster_assignment, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBScan\n",
    "\n",
    "# Define number of clusters to show (note number of clusters is automatically determined)\n",
    "num_clusters = 75\n",
    "\n",
    "# Reduce Dimentions using TSNE\n",
    "topics_red = reduce_dims(topics_embeddings,alg='tsne',num_components=3)\n",
    "\n",
    "# Apply DBScan Clustering\n",
    "cluster_assignment = dbscan(data=topics_embeddings) # data=topics_embeddings, topics_red\n",
    "\n",
    "# Print clusters cohesively\n",
    "print_clusters(num_clusters, cluster_assignment, topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
